"""
DailyInfo - ë°ì´í„° ì •ë³´ ëŒ€ì‹œë³´ë“œ
ì‹¤ì‹œê°„ ìŒì•… ì°¨íŠ¸, ë‚ ì”¨, ë‰´ìŠ¤ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” Streamlit ì• í”Œë¦¬ì¼€ì´ì…˜
"""

import streamlit as st
import requests
import json
import time
from datetime import datetime
import pytz
import pandas as pd
import plotly.express as px
from typing import List, Dict, Optional, Tuple
import asyncio
import aiohttp
from bs4 import BeautifulSoup
import re
from dataclasses import dataclass
from enum import Enum

# ìƒìˆ˜ ì •ì˜
class Constants:
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒìˆ˜"""
    CACHE_DURATION = 300  # 5ë¶„ ìºì‹œ
    REQUEST_TIMEOUT = 10  # ìš”ì²­ íƒ€ì„ì•„ì›ƒ (ì´ˆ)
    MAX_CHART_ITEMS = 100  # ìµœëŒ€ ì°¨íŠ¸ í•­ëª© ìˆ˜
    
    # URL
    BUGS_CHART_URL = "https://music.bugs.co.kr/chart/track/realtime/total?wl_ref=M_contents_03_01"
    GOOGLE_NEWS_RSS_URL = "https://news.google.com/rss?hl=ko&gl=KR&ceid=KR:ko"
    ALADIN_BESTSELLER_URL = "https://www.aladin.co.kr/shop/common/wbest.aspx?BestType=NowBest&BranchType=2&CID=0&page={}&cnt=100&SortOrder=1"
    
    # HTTP í—¤ë”
    DEFAULT_HEADERS = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'ko-KR,ko;q=0.9,en;q=0.8',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
    }
    
    # ì„œìš¸ ì¢Œí‘œ
    SEOUL_LAT = 37.5665
    SEOUL_LON = 126.9780
    
    # í•œêµ­ ì‹œê°„ëŒ€
    KOREA_TZ = pytz.timezone('Asia/Seoul')

class ChartRange(Enum):
    """ì°¨íŠ¸ í‘œì‹œ ë²”ìœ„"""
    TOP_10 = 10
    TOP_20 = 20
    TOP_50 = 50
    TOP_100 = 100

@dataclass
class WeatherData:
    """ë‚ ì”¨ ë°ì´í„° í´ë˜ìŠ¤"""
    temperature: float
    humidity: int
    description: str
    wind_speed: float
    wind_direction: int

@dataclass
class NewsData:
    """ë‰´ìŠ¤ ë°ì´í„° í´ë˜ìŠ¤"""
    title: str
    link: str
    source: str
    published: str

@dataclass
class BookData:
    """ë„ì„œ ë°ì´í„° í´ë˜ìŠ¤"""
    rank: int
    title: str
    author: str
    publisher: str

class DataFetcher:
    """ë°ì´í„° ìˆ˜ì§‘ì„ ìœ„í•œ í´ë˜ìŠ¤"""
    
    @staticmethod
    def get_bugs_chart() -> List[str]:
        """ë²…ìŠ¤ ì°¨íŠ¸ ë°ì´í„° í¬ë¡¤ë§"""
        try:
            response = requests.get(
                Constants.BUGS_CHART_URL, 
                headers=Constants.DEFAULT_HEADERS, 
                timeout=Constants.REQUEST_TIMEOUT
            )
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            chart_data = DataFetcher._parse_bugs_chart(soup)
            
            if not chart_data:
                st.error("ë²…ìŠ¤ ì°¨íŠ¸ ë°ì´í„°ë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì›¹ì‚¬ì´íŠ¸ êµ¬ì¡°ê°€ ë³€ê²½ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                return []
            
            return chart_data
            
        except requests.exceptions.RequestException as e:
            st.error(f"ë²…ìŠ¤ ì°¨íŠ¸ ì›¹ì‚¬ì´íŠ¸ì— ì ‘ì†í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
            return []
        except Exception as e:
            st.error(f"ë²…ìŠ¤ ì°¨íŠ¸ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return []
    
    @staticmethod
    def _parse_bugs_chart(soup: BeautifulSoup) -> List[str]:
        """ë²…ìŠ¤ ì°¨íŠ¸ HTML íŒŒì‹±"""
        chart_data = []
        
        # ì°¨íŠ¸ í…Œì´ë¸” ì°¾ê¸°
        table = soup.find('table', class_='list')
        
        if not table:
            st.warning("ì°¨íŠ¸ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì›¹ì‚¬ì´íŠ¸ êµ¬ì¡°ê°€ ë³€ê²½ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            return chart_data
        
        rows = table.find_all('tr')[1:]  # í—¤ë” ì œì™¸
        
        for row in rows:
            if len(chart_data) >= Constants.MAX_CHART_ITEMS:
                break
                
            cells = row.find_all('td')
            if len(cells) < 6:  # ìµœì†Œ 6ê°œ ì…€ì´ í•„ìš”
                continue
            
            chart_item = DataFetcher._extract_chart_item(cells, row)
            if chart_item:
                chart_data.append(chart_item)
        
        return chart_data
    
    @staticmethod
    def _extract_chart_item(cells: List, row) -> Optional[str]:
        """ì°¨íŠ¸ í•­ëª© ì¶”ì¶œ"""
        try:
            # ìˆœìœ„ ì¶”ì¶œ (ranking divì—ì„œ)
            rank = "N/A"
            ranking_div = row.find('div', class_='ranking')
            if ranking_div:
                strong_tag = ranking_div.find('strong')
                if strong_tag:
                    rank = strong_tag.get_text(strip=True)
            
            # ê³¡ëª… ì¶”ì¶œ (ì•¨ë²” ì…€ì—ì„œ - 6ë²ˆì§¸ ì…€)
            song_title = cells[5].get_text(strip=True) if len(cells) > 5 else "N/A"
            
            # ì•„í‹°ìŠ¤íŠ¸ ì¶”ì¶œ (ì•„í‹°ìŠ¤íŠ¸ ë§í¬ì—ì„œ)
            artist_name = "N/A"
            artist_link = row.find('a', href=re.compile(r'/artist/'))
            if artist_link:
                artist_name = artist_link.get_text(strip=True)
            
            if song_title and artist_name and song_title != "N/A" and artist_name != "N/A":
                return f"{rank}. {artist_name} - {song_title}"
            
        except Exception:
            pass
        
        return None
    


    @staticmethod
    def get_book_rankings() -> List[BookData]:
        """ì•Œë¼ë”˜ ì‹¤ì‹œê°„ ë² ìŠ¤íŠ¸ì…€ëŸ¬ ë°ì´í„° (100ê°œ)"""
        try:
            book_data = []
            
            # ë‘ í˜ì´ì§€ì—ì„œ ê°ê° 50ê°œì”© ê°€ì ¸ì˜¤ê¸°
            for page in [1, 2]:
                url = Constants.ALADIN_BESTSELLER_URL.format(page)
                response = requests.get(url, headers=Constants.DEFAULT_HEADERS, timeout=Constants.REQUEST_TIMEOUT)
                response.raise_for_status()
                
                soup = BeautifulSoup(response.content, 'html.parser')
                page_data = DataFetcher._parse_aladin_chart(soup, page)
                
                # ë‘ ë²ˆì§¸ í˜ì´ì§€ ë°ì´í„°ì˜ ìˆœìœ„ë¥¼ 51-100ìœ¼ë¡œ ì¡°ì •
                if page == 2:
                    for book in page_data:
                        book.rank = book.rank + 50
                
                book_data.extend(page_data)
            
            return book_data
            
        except requests.exceptions.RequestException as e:
            st.error(f"ì•Œë¼ë”˜ ì›¹ì‚¬ì´íŠ¸ì— ì ‘ì†í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
            return []
        except Exception as e:
            st.error(f"ë„ì„œ ìˆœìœ„ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return []
    
    @staticmethod
    def _parse_aladin_chart(soup: BeautifulSoup, page: int = 1) -> List[BookData]:
        """ì•Œë¼ë”˜ ë² ìŠ¤íŠ¸ì…€ëŸ¬ HTML íŒŒì‹±"""
        book_data = []
        
        try:
            # 1. ss_book_list í´ë˜ìŠ¤ë¥¼ ê°€ì§„ ìš”ì†Œë“¤ì—ì„œ ì±… ì •ë³´ ì¶”ì¶œ
            book_lists = soup.find_all('div', class_='ss_book_list')
            
            if book_lists:
                for i, book_list in enumerate(book_lists[:50]):  # ìµœëŒ€ 50ê°œ
                    book_list_text = book_list.get_text(strip=True)
                    
                    # ìˆœìœ„ì™€ ì œëª© íŒ¨í„´ ì°¾ê¸°
                    # íŒ¨í„´ 1: ìˆ«ì + ì œëª© (ë” ì •í™•í•œ íŒ¨í„´)
                    pattern1 = r'(\d+)\.\s*([ê°€-í£\s]+?)(?:\s+ì§€ìŒ|\s+ì €|\s+í¸ì§‘|\s+ê¸€|\s+ê·¸ë¦¼|\s+ì™¸|\s*\[|\s*$)'
                    matches1 = re.findall(pattern1, book_list_text)
                    
                    # íŒ¨í„´ 2: [êµ­ë‚´ë„ì„œ] + ì œëª©
                    pattern2 = r'\[êµ­ë‚´ë„ì„œ\]([ê°€-í£\s]+?)(?:\s+ì§€ìŒ|\s+ì €|\s+í¸ì§‘|\s+ê¸€|\s+ê·¸ë¦¼|\s+ì™¸|\s*\[|\s*$)'
                    matches2 = re.findall(pattern2, book_list_text)
                    
                    if matches1:
                        for match in matches1:
                            rank = int(match[0])
                            title = match[1].strip()
                            
                            if len(title) > 3:  # ìœ íš¨í•œ ì œëª©ì¸ì§€ í™•ì¸
                                # ì €ìì™€ ì¶œíŒì‚¬ ì •ë³´ ì¶”ì¶œ ì‹œë„
                                author = "ì €ì ì •ë³´ ì—†ìŒ"
                                publisher = "ì¶œíŒì‚¬ ì •ë³´ ì—†ìŒ"
                                
                                # ì €ì íŒ¨í„´ ì°¾ê¸°
                                author_pattern = r'([ê°€-í£\s]+?)\s*ì§€ìŒ|([ê°€-í£\s]+?)\s*ì €|([ê°€-í£\s]+?)\s*í¸ì§‘'
                                author_matches = re.findall(author_pattern, book_list_text)
                                if author_matches:
                                    for author_match in author_matches:
                                        if any(author_match):
                                            author = next(a for a in author_match if a).strip()
                                            break
                                
                                # ì¶œíŒì‚¬ íŒ¨í„´ ì°¾ê¸° (ì €ì ë‹¤ìŒì— ë‚˜ì˜¤ëŠ” ê²½ìš°)
                                publisher_pattern = r'([ê°€-í£\s]+?)\s*\|\s*([ê°€-í£\s]+?)\s*\|'
                                publisher_matches = re.findall(publisher_pattern, book_list_text)
                                if publisher_matches:
                                    publisher = publisher_matches[0][1].strip()
                                
                                # ì¤‘ë³µ ì œê±°
                                existing_titles = [book.title for book in book_data]
                                if title not in existing_titles:
                                    book_data.append(BookData(rank, title, author, publisher))
                                break  # ì²« ë²ˆì§¸ ë§¤ì¹˜ë§Œ ì‚¬ìš©
                
                elif matches2:
                    # íŒ¨í„´2ë¡œ ì°¾ì€ ê²½ìš° ìˆœìœ„ëŠ” ì¸ë±ìŠ¤ ê¸°ë°˜ìœ¼ë¡œ ì„¤ì •
                    for i, match in enumerate(matches2):
                        rank = i + 1
                        title = match.strip()
                        
                        if len(title) > 3:  # ìœ íš¨í•œ ì œëª©ì¸ì§€ í™•ì¸
                            # ì €ìì™€ ì¶œíŒì‚¬ ì •ë³´ ì¶”ì¶œ ì‹œë„
                            author = "ì €ì ì •ë³´ ì—†ìŒ"
                            publisher = "ì¶œíŒì‚¬ ì •ë³´ ì—†ìŒ"
                            
                            # ì €ì íŒ¨í„´ ì°¾ê¸°
                            author_pattern = r'([ê°€-í£\s]+?)\s*ì§€ìŒ|([ê°€-í£\s]+?)\s*ì €|([ê°€-í£\s]+?)\s*í¸ì§‘'
                            author_matches = re.findall(author_pattern, book_list_text)
                            if author_matches:
                                for author_match in author_matches:
                                    if any(author_match):
                                        author = next(a for a in author_match if a).strip()
                                        break
                            
                            # ì¶œíŒì‚¬ íŒ¨í„´ ì°¾ê¸° (ì €ì ë‹¤ìŒì— ë‚˜ì˜¤ëŠ” ê²½ìš°)
                            publisher_pattern = r'([ê°€-í£\s]+?)\s*\|\s*([ê°€-í£\s]+?)\s*\|'
                            publisher_matches = re.findall(publisher_pattern, book_list_text)
                            if publisher_matches:
                                publisher = publisher_matches[0][1].strip()
                            
                            # ì¤‘ë³µ ì œê±°
                            existing_titles = [book.title for book in book_data]
                            if title not in existing_titles:
                                book_data.append(BookData(rank, title, author, publisher))
                            break  # ì²« ë²ˆì§¸ ë§¤ì¹˜ë§Œ ì‚¬ìš©
            
            # 2. ì±… ìƒí’ˆ ë§í¬ì—ì„œ ì œëª© ì¶”ì¶œ
            if not book_data:
                book_links = soup.find_all('a', href=lambda x: x and 'wproduct.aspx' in x)
                
                for i, link in enumerate(book_links[:50]):
                    link_text = link.get_text(strip=True)
                    if len(link_text) > 5 and not link_text.startswith('http'):
                        # ìˆœìœ„ëŠ” ì¸ë±ìŠ¤ ê¸°ë°˜ìœ¼ë¡œ ì„¤ì •
                        rank = i + 1
                        title = link_text
                        
                        # ì €ìì™€ ì¶œíŒì‚¬ëŠ” ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
                        author = "ì €ì ì •ë³´ ì—†ìŒ"
                        publisher = "ì¶œíŒì‚¬ ì •ë³´ ì—†ìŒ"
                        
                        # ì¤‘ë³µ ì œê±°
                        existing_titles = [book.title for book in book_data]
                        if title not in existing_titles:
                            book_data.append(BookData(rank, title, author, publisher))
            
            # 3. ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ë°ì´í„° ì¶”ì¶œ ì‹œë„
            if not book_data:
                all_text = soup.get_text()
                
                # ì•Œë¼ë”˜ ë² ìŠ¤íŠ¸ì…€ëŸ¬ íŒ¨í„´ìœ¼ë¡œ ì±… ì •ë³´ ì¶”ì¶œ ì‹œë„
                patterns = [
                    r'(\d+)\.\s*([ê°€-í£\s]+?)(?:\s+ì§€ìŒ|\s+ì €|\s+í¸ì§‘|\s+ê¸€|\s+ê·¸ë¦¼|\s+ì™¸)',
                    r'(\d+)\s*([ê°€-í£\s]+?)(?:\s+ì§€ìŒ|\s+ì €|\s+í¸ì§‘|\s+ê¸€|\s+ê·¸ë¦¼|\s+ì™¸)',
                    r'ìˆœìœ„\s*(\d+)[^ê°€-í£]*([ê°€-í£\s]+?)(?:\s+ì§€ìŒ|\s+ì €|\s+í¸ì§‘|\s+ê¸€|\s+ê·¸ë¦¼|\s+ì™¸)',
                ]
                
                for pattern in patterns:
                    matches = re.findall(pattern, all_text)
                    if matches:
                        for match in matches[:50]:  # ìµœëŒ€ 50ê°œ
                            rank = int(match[0])
                            title = match[1].strip()
                            
                            if len(title) > 3:  # ìœ íš¨í•œ ì œëª©ì¸ì§€ í™•ì¸
                                # ì €ìì™€ ì¶œíŒì‚¬ëŠ” ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
                                author = "ì €ì ì •ë³´ ì—†ìŒ"
                                publisher = "ì¶œíŒì‚¬ ì •ë³´ ì—†ìŒ"
                                
                                # ì¤‘ë³µ ì œê±°
                                existing_titles = [book.title for book in book_data]
                                if title not in existing_titles:
                                    book_data.append(BookData(rank, title, author, publisher))
                        break
            
            # ìˆœìœ„ë³„ë¡œ ì •ë ¬
            book_data.sort(key=lambda x: x.rank)
            
            # ì„±ê³µì ìœ¼ë¡œ ë°ì´í„°ë¥¼ íŒŒì‹±í•œ ê²½ìš° ì„¸ì…˜ì— ì €ì¥
            if book_data:
                st.session_state.last_successful_book_data = book_data.copy()
                st.session_state.last_successful_book_update = time.time()
                return book_data
            
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
            return []
            
        except Exception as e:
            st.error(f"ì•Œë¼ë”˜ ì°¨íŠ¸ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
            return []

    @staticmethod
    def get_weather_info() -> Optional[WeatherData]:
        """ë‚ ì”¨ ì •ë³´ ìˆ˜ì§‘"""
        try:
            # Streamlit secretsì—ì„œ ë¨¼ì € ì‹œë„, ì—†ìœ¼ë©´ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì‹œë„
            weather_api_key = st.secrets.get("WEATHER_API_KEY", "")
            if not weather_api_key:
                import os
                weather_api_key = os.environ.get("WEATHER_API_KEY", "")
            
            if not weather_api_key or weather_api_key == "your_api_key_here":
                st.error("OpenWeatherMap API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit Cloudì˜ Settings > Secretsì—ì„œ WEATHER_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
                return None
            
            url = f"https://api.openweathermap.org/data/2.5/weather"
            params = {
                'lat': Constants.SEOUL_LAT,
                'lon': Constants.SEOUL_LON,
                'appid': weather_api_key,
                'units': 'metric',
                'lang': 'kr'
            }
            
            response = requests.get(url, params=params, timeout=Constants.REQUEST_TIMEOUT)
            
            if response.status_code == 200:
                data = response.json()
                return WeatherData(
                    temperature=data["main"]["temp"],
                    humidity=data["main"]["humidity"],
                    description=data["weather"][0]["description"],
                    wind_speed=data["wind"]["speed"],
                    wind_direction=data["wind"]["deg"]
                )
            else:
                st.error(f"ë‚ ì”¨ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ìƒíƒœ ì½”ë“œ: {response.status_code})")
                return None
                
        except Exception as e:
            st.error(f"ë‚ ì”¨ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
            return None

    @staticmethod
    def get_news() -> List[NewsData]:
        """Google ë‰´ìŠ¤ RSS í”¼ë“œì—ì„œ ë‰´ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        try:
            import xml.etree.ElementTree as ET
            from datetime import datetime
            
            # Google ë‰´ìŠ¤ RSS í”¼ë“œ ìš”ì²­
            response = requests.get(Constants.GOOGLE_NEWS_RSS_URL, 
                                  headers=Constants.DEFAULT_HEADERS, 
                                  timeout=Constants.REQUEST_TIMEOUT)
            response.raise_for_status()
            
            # XML íŒŒì‹±
            root = ET.fromstring(response.content)
            
            news_data = []
            
            # RSS í”¼ë“œì—ì„œ ë‰´ìŠ¤ í•­ëª© ì¶”ì¶œ
            for item in root.findall('.//item'):
                title_elem = item.find('title')
                link_elem = item.find('link')
                pub_date_elem = item.find('pubDate')
                
                if title_elem is not None and link_elem is not None:
                    title = title_elem.text.strip()
                    link = link_elem.text.strip()
                    
                    # ì œëª©ì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ë¹„ì–´ìˆìœ¼ë©´ ê±´ë„ˆë›°ê¸°
                    if len(title) < 5:
                        continue
                    
                    # ì¶œì²˜ ì¶”ì¶œ (ì œëª©ì—ì„œ ë§ˆì§€ë§‰ ê´„í˜¸ ë¶€ë¶„)
                    source = "Google ë‰´ìŠ¤"
                    if " - " in title:
                        title_parts = title.split(" - ")
                        if len(title_parts) >= 2:
                            title = " - ".join(title_parts[:-1])
                            source = title_parts[-1]
                    
                    # ë‚ ì§œ íŒŒì‹±
                    published = "ìµœê·¼"
                    if pub_date_elem is not None:
                        try:
                            # RFC 822 í˜•ì‹ì˜ ë‚ ì§œë¥¼ íŒŒì‹± (UTC ê¸°ì¤€)
                            date_str = pub_date_elem.text.strip()
                            date_obj = datetime.strptime(date_str, "%a, %d %b %Y %H:%M:%S %Z")
                            
                            # UTCë¥¼ í•œêµ­ ì‹œê°„ìœ¼ë¡œ ë³€í™˜
                            utc_tz = pytz.UTC
                            utc_time = utc_tz.localize(date_obj)
                            korea_time = utc_time.astimezone(Constants.KOREA_TZ)
                            
                            published = korea_time.strftime("%Y-%m-%d %H:%M")
                        except:
                            published = "ìµœê·¼"
                    
                    # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•´ ì´ë¯¸ ì¶”ê°€ëœ ì œëª©ì¸ì§€ í™•ì¸
                    existing_titles = [news.title for news in news_data]
                    if title not in existing_titles:
                        news_data.append(NewsData(title, link, source, published))
            
            return news_data[:20]  # ìƒìœ„ 20ê°œ ë‰´ìŠ¤ë§Œ ë°˜í™˜
            
        except requests.exceptions.RequestException as e:
            st.error(f"Google ë‰´ìŠ¤ RSS í”¼ë“œì— ì ‘ì†í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
            return []
        except Exception as e:
            st.error(f"ë‰´ìŠ¤ ë°ì´í„°ë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
            return []

class DataProcessor:
    """ë°ì´í„° ì²˜ë¦¬ ë° ì‹œê°í™” í´ë˜ìŠ¤"""
    
    @staticmethod
    def create_chart_dataframe(data: List[str]) -> pd.DataFrame:
        """ì°¨íŠ¸ ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜"""
        df_data = []
        
        for item in data:
            chart_item = DataProcessor._parse_chart_item(item)
            if chart_item:
                df_data.append(chart_item)
        
        return pd.DataFrame(df_data)
    
    @staticmethod
    def _parse_chart_item(item: str) -> Optional[Dict]:
        """ì°¨íŠ¸ í•­ëª© íŒŒì‹±"""
        try:
            if " - " not in item:
                return None
                
            rank, song_info = item.split(". ", 1)
            if " - " not in song_info:
                return None
                
            artist, title = song_info.split(" - ", 1)
            
            return {
                "ìˆœìœ„": int(rank),
                "ì•„í‹°ìŠ¤íŠ¸": artist,
                "ê³¡ëª…": title
            }
        except Exception:
            return None

    @staticmethod
    def create_weather_display(weather_data: WeatherData) -> None:
        """ë‚ ì”¨ ì •ë³´ í‘œì‹œ"""
        if not weather_data:
            return
            
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ê¸°ì˜¨", f"{weather_data.temperature}Â°C")
        with col2:
            st.metric("ìŠµë„", f"{weather_data.humidity}%")
        with col3:
            st.metric("ë°”ëŒ", f"{weather_data.wind_speed} m/s")
        with col4:
            st.metric("ë‚ ì”¨", weather_data.description)

class CacheManager:
    """ìºì‹œ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    @staticmethod
    def get_cached_data(key: str, fetcher_func, *args):
        """ìºì‹œëœ ë°ì´í„° ë°˜í™˜ ë˜ëŠ” ìƒˆë¡œ ìˆ˜ì§‘"""
        current_time = time.time()
        
        # ìºì‹œ í™•ì¸
        if (key in st.session_state.data_cache and 
            key in st.session_state.last_update and
            current_time - st.session_state.last_update[key] < Constants.CACHE_DURATION):
            return st.session_state.data_cache[key]
        
        # ìƒˆ ë°ì´í„° ìˆ˜ì§‘
        with st.spinner(f"{key} ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ì¤‘..."):
            data = fetcher_func(*args)
            st.session_state.data_cache[key] = data
            st.session_state.last_update[key] = current_time
        
        return data
    
    @staticmethod
    def clear_cache():
        """ìºì‹œ ì´ˆê¸°í™”"""
        st.session_state.data_cache.clear()
        st.session_state.last_update.clear()

class UIComponents:
    """UI ì»´í¬ë„ŒíŠ¸ í´ë˜ìŠ¤"""
    
    @staticmethod
    def setup_page():
        """í˜ì´ì§€ ì„¤ì •"""
        st.set_page_config(
            page_title="DailyInfo - ë°ì´í„° ì •ë³´ ëŒ€ì‹œë³´ë“œ",
            page_icon="ğŸ“Š",
            layout="wide",
            initial_sidebar_state="expanded"
        )
        
        # CSS ìŠ¤íƒ€ì¼ ì¶”ê°€
        st.markdown("""
        <style>
            .main-header {
                font-size: 2.5rem;
                color: #1f77b4;
                text-align: center;
                margin-bottom: 2rem;
            }
            .metric-card {
                background-color: #f0f2f6;
                padding: 1rem;
                border-radius: 0.5rem;
                border-left: 4px solid #1f77b4;
            }
            .loading-spinner {
                text-align: center;
                padding: 2rem;
            }
        </style>
        """, unsafe_allow_html=True)
    
    @staticmethod
    def initialize_session_state():
        """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
        if 'data_cache' not in st.session_state:
            st.session_state.data_cache = {}
        if 'last_update' not in st.session_state:
            st.session_state.last_update = {}
        if 'last_successful_book_data' not in st.session_state:
            st.session_state.last_successful_book_data = []
        if 'last_successful_book_update' not in st.session_state:
            st.session_state.last_successful_book_update = None
    
    @staticmethod
    def create_sidebar() -> str:
        """ì‚¬ì´ë“œë°” ìƒì„±"""
        st.sidebar.title("ğŸ“‹ ë©”ë‰´")
        menu = st.sidebar.selectbox(
            "ë³´ê³  ì‹¶ì€ ì •ë³´ë¥¼ ì„ íƒí•˜ì„¸ìš”",
            [
                "ğŸ  ëŒ€ì‹œë³´ë“œ ê°œìš”",
                "ğŸµ ë²…ìŠ¤ ì¼ê°„ ì°¨íŠ¸", 
                "ğŸ“š ë„ì„œ ìˆœìœ„",
                "ğŸŒ¤ï¸ ë‚ ì”¨ ì •ë³´",
                "ğŸ“° ë‰´ìŠ¤",
                "âš™ï¸ ì„¤ì •"
            ]
        )
        return menu

class PageHandlers:
    """í˜ì´ì§€ í•¸ë“¤ëŸ¬ í´ë˜ìŠ¤"""
    
    @staticmethod
    def show_dashboard_overview():
        """ëŒ€ì‹œë³´ë“œ ê°œìš” í˜ì´ì§€"""
        st.header("ğŸ“Š ëŒ€ì‹œë³´ë“œ ê°œìš”")
        st.caption("ğŸ•’ ëª¨ë“  ì‹œê°„ì€ í•œêµ­ ì‹œê°„(UTC+9) ê¸°ì¤€ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤.")
        
        # ë©”íŠ¸ë¦­ ì¹´ë“œë“¤
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.markdown("""
            <div class="metric-card">
                <h3>ğŸµ ìŒì•… ì°¨íŠ¸</h3>
                <p>ë²…ìŠ¤ ì‹¤ì‹œê°„ ì°¨íŠ¸ TOP 100</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown("""
            <div class="metric-card">
                <h3>ğŸ“š ë„ì„œ ì •ë³´</h3>
                <p>ë² ìŠ¤íŠ¸ì…€ëŸ¬ ìˆœìœ„</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            st.markdown("""
            <div class="metric-card">
                <h3>ğŸŒ¤ï¸ ë‚ ì”¨ ì •ë³´</h3>
                <p>ì„œìš¸ ì‹¤ì‹œê°„ ë‚ ì”¨</p>
            </div>
            """, unsafe_allow_html=True)
            
        with col4:
            st.markdown("""
            <div class="metric-card">
                <h3>ğŸ“° ë‰´ìŠ¤ ì •ë³´</h3>
                <p>Google ë‰´ìŠ¤ ì‹¤ì‹œê°„ í—¤ë“œë¼ì¸</p>
            </div>
            """, unsafe_allow_html=True)
        
        # ìµœê·¼ ì—…ë°ì´íŠ¸ ì •ë³´
        st.subheader("ğŸ•’ ìµœê·¼ ì—…ë°ì´íŠ¸ (í•œêµ­ ì‹œê°„)")
        if st.session_state.last_update:
            for key, timestamp in st.session_state.last_update.items():
                # UTC íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ í•œêµ­ ì‹œê°„ìœ¼ë¡œ ë³€í™˜
                utc_time = datetime.utcfromtimestamp(timestamp)
                utc_tz = pytz.UTC
                utc_time = utc_tz.localize(utc_time)
                korea_time = utc_time.astimezone(Constants.KOREA_TZ)
                update_time = korea_time.strftime("%Y-%m-%d %H:%M:%S")
                st.write(f"**{key}**: {update_time}")

    @staticmethod
    def show_bugs_chart():
        """ë²…ìŠ¤ ì°¨íŠ¸ í˜ì´ì§€"""
        st.header("ğŸµ ë²…ìŠ¤ ì¼ê°„ ì°¨íŠ¸ TOP 100")
        
        # ë°ì´í„° ì¶œì²˜ ì •ë³´
        st.info("ğŸ“¡ ì‹¤ì‹œê°„ ë²…ìŠ¤ ì°¨íŠ¸ ë°ì´í„°ë¥¼ í¬ë¡¤ë§í•˜ì—¬ ì œê³µí•©ë‹ˆë‹¤.")
        
        data = CacheManager.get_cached_data("bugs_chart", DataFetcher.get_bugs_chart)
        
        if data:
            # í‘œì‹œí•  ìˆœìœ„ ë²”ìœ„ ì„ íƒ
            col1, col2 = st.columns([1, 3])
            with col1:
                display_range = st.selectbox(
                    "í‘œì‹œí•  ìˆœìœ„ ë²”ìœ„",
                    ["TOP 10", "TOP 20", "TOP 50", "TOP 100"],
                    index=0
                )
            
            # ì„ íƒëœ ë²”ìœ„ì— ë”°ë¼ ë°ì´í„° í•„í„°ë§
            range_map = {f"TOP {v.value}": v.value for v in ChartRange}
            display_count = range_map[display_range]
            filtered_data = data[:display_count]
            
            # ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ í‘œì‹œ
            df = DataProcessor.create_chart_dataframe(filtered_data)
            
            if not df.empty:
                # ë°ì´í„° í…Œì´ë¸” í‘œì‹œ
                st.subheader(f"ğŸ“‹ {display_range} ì°¨íŠ¸")
                st.dataframe(df, use_container_width=True, hide_index=True)
                
                # ì°¨íŠ¸ ì‹œê°í™”
                st.subheader("ğŸ“Š ì°¨íŠ¸ ì‹œê°í™”")
                fig = px.bar(df, x="ê³¡ëª…", y="ìˆœìœ„", 
                            title=f"ë²…ìŠ¤ ì°¨íŠ¸ {display_range}",
                            color="ì•„í‹°ìŠ¤íŠ¸",
                            height=600)
                fig.update_layout(
                    xaxis_tickangle=-45,
                    showlegend=True
                )
                st.plotly_chart(fig, use_container_width=True)
                
                # ì•„í‹°ìŠ¤íŠ¸ë³„ í†µê³„
                st.subheader("ğŸ¤ ì•„í‹°ìŠ¤íŠ¸ë³„ í†µê³„")
                artist_stats = df['ì•„í‹°ìŠ¤íŠ¸'].value_counts()
                fig_pie = px.pie(
                    values=artist_stats.values, 
                    names=artist_stats.index,
                    title="ì•„í‹°ìŠ¤íŠ¸ë³„ TOP 100 ì§„ì… ê³¡ ìˆ˜"
                )
                st.plotly_chart(fig_pie, use_container_width=True)
            else:
                st.write("ë°ì´í„°ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    @staticmethod
    def show_book_rankings():
        """ë„ì„œ ìˆœìœ„ í˜ì´ì§€"""
        st.header("ğŸ“š ì•Œë¼ë”˜ ë² ìŠ¤íŠ¸ì…€ëŸ¬ TOP 100")
        
        # ë°ì´í„° ì¶œì²˜ ì •ë³´
        st.info("ğŸ“¡ ì•Œë¼ë”˜ ë² ìŠ¤íŠ¸ì…€ëŸ¬ ë°ì´í„°ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ í¬ë¡¤ë§í•˜ì—¬ ì œê³µí•©ë‹ˆë‹¤.")
        
        data = CacheManager.get_cached_data("book_rankings", DataFetcher.get_book_rankings)
        
        # ì‹¤ì‹œê°„ ë°ì´í„°ê°€ ì—†ê³  ìµœê·¼ ì„±ê³µí•œ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°
        if not data and st.session_state.last_successful_book_data:
            st.warning("âš ï¸ ì‹¤ì‹œê°„ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ì–´ ìµœê·¼ì— ì„±ê³µí•œ ë°ì´í„°ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.")
            
            # ìµœê·¼ ì„±ê³µí•œ ë°ì´í„°ì˜ ì—…ë°ì´íŠ¸ ì‹œê°„ í‘œì‹œ
            if st.session_state.last_successful_book_update:
                utc_time = datetime.utcfromtimestamp(st.session_state.last_successful_book_update)
                utc_tz = pytz.UTC
                utc_time = utc_tz.localize(utc_time)
                korea_time = utc_time.astimezone(Constants.KOREA_TZ)
                update_time = korea_time.strftime("%Y-%m-%d %H:%M:%S")
                st.caption(f"ğŸ“… ë§ˆì§€ë§‰ ì„±ê³µí•œ ë°ì´í„° ì—…ë°ì´íŠ¸: {update_time} (í•œêµ­ ì‹œê°„)")
            
            data = st.session_state.last_successful_book_data
        
        if data:
            # í‘œì‹œí•  ìˆœìœ„ ë²”ìœ„ ì„ íƒ
            col1, col2 = st.columns([1, 3])
            with col1:
                display_range = st.selectbox(
                    "í‘œì‹œí•  ìˆœìœ„ ë²”ìœ„",
                    ["TOP 10", "TOP 20", "TOP 50", "TOP 100"],
                    index=0
                )
            
            # ì„ íƒëœ ë²”ìœ„ì— ë”°ë¼ ë°ì´í„° í•„í„°ë§
            range_map = {f"TOP {v.value}": v.value for v in ChartRange}
            display_count = range_map[display_range]
            filtered_data = data[:display_count]
            
            # BookDataë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            book_dicts = [
                {"rank": book.rank, "title": book.title, "author": book.author, "publisher": book.publisher}
                for book in filtered_data
            ]
            df = pd.DataFrame(book_dicts)
            
            if not df.empty:
                # ë°ì´í„° í…Œì´ë¸” í‘œì‹œ
                st.subheader(f"ğŸ“‹ {display_range} ë² ìŠ¤íŠ¸ì…€ëŸ¬")
                st.dataframe(df, use_container_width=True, hide_index=True)
                
                # ì°¨íŠ¸ ì‹œê°í™”
                st.subheader("ğŸ“Š ì°¨íŠ¸ ì‹œê°í™”")
                fig = px.bar(df, x="title", y="rank", 
                            title=f"ì•Œë¼ë”˜ ë² ìŠ¤íŠ¸ì…€ëŸ¬ {display_range}",
                            color="publisher",
                            height=600)
                fig.update_layout(
                    xaxis_tickangle=-45,
                    showlegend=True
                )
                st.plotly_chart(fig, use_container_width=True)
                
                # ì¶œíŒì‚¬ë³„ í†µê³„
                st.subheader("ğŸ¢ ì¶œíŒì‚¬ë³„ í†µê³„")
                publisher_stats = df['publisher'].value_counts()
                fig_pie = px.pie(
                    values=publisher_stats.values, 
                    names=publisher_stats.index,
                    title=f"ì¶œíŒì‚¬ë³„ {display_range} ë² ìŠ¤íŠ¸ì…€ëŸ¬ ë¶„í¬"
                )
                st.plotly_chart(fig_pie, use_container_width=True)
                
                # ì €ìë³„ í†µê³„
                st.subheader("âœï¸ ì €ìë³„ í†µê³„")
                author_stats = df['author'].value_counts()
                fig_author = px.bar(
                    x=author_stats.index,
                    y=author_stats.values,
                    title=f"ì €ìë³„ {display_range} ë² ìŠ¤íŠ¸ì…€ëŸ¬ ìˆ˜",
                    labels={'x': 'ì €ì', 'y': 'ë² ìŠ¤íŠ¸ì…€ëŸ¬ ìˆ˜'}
                )
                fig_author.update_layout(xaxis_tickangle=-45)
                st.plotly_chart(fig_author, use_container_width=True)
            else:
                st.write("ë°ì´í„°ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    @staticmethod
    def show_weather_info():
        """ë‚ ì”¨ ì •ë³´ í˜ì´ì§€"""
        st.header("ğŸŒ¤ï¸ ì„œìš¸ ë‚ ì”¨ ì •ë³´")
        
        weather_data = CacheManager.get_cached_data("weather_info", DataFetcher.get_weather_info)
        
        if weather_data:
            DataProcessor.create_weather_display(weather_data)
            
            # ë‚ ì”¨ ì„¤ëª…
            st.subheader("ğŸ“ ë‚ ì”¨ ìƒì„¸ ì •ë³´")
            st.write(f"í˜„ì¬ ì„œìš¸ì˜ ë‚ ì”¨ëŠ” **{weather_data.description}**ì…ë‹ˆë‹¤.")
            st.write(f"ê¸°ì˜¨: {weather_data.temperature}Â°C, ìŠµë„: {weather_data.humidity}%")
            st.write(f"ë°”ëŒ: {weather_data.wind_speed} m/s")

    @staticmethod
    def show_news():
        """ë‰´ìŠ¤ í˜ì´ì§€"""
        st.header("ğŸ“° Google ë‰´ìŠ¤ ì‹¤ì‹œê°„ í—¤ë“œë¼ì¸")
        st.caption("ğŸ•’ ëª¨ë“  ì‹œê°„ì€ í•œêµ­ ì‹œê°„(UTC+9) ê¸°ì¤€ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤.")
        
        # ë°ì´í„° ì¶œì²˜ ì •ë³´
        st.info("ğŸ“¡ Google ë‰´ìŠ¤ RSS í”¼ë“œì—ì„œ ì‹¤ì‹œê°„ìœ¼ë¡œ ìµœì‹  ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.")
        
        news_data = CacheManager.get_cached_data("news", DataFetcher.get_news)
        
        if news_data:
            # í‘œì‹œí•  ë‰´ìŠ¤ ê°œìˆ˜ ì„ íƒ
            col1, col2 = st.columns([1, 3])
            with col1:
                display_count = st.selectbox(
                    "í‘œì‹œí•  ë‰´ìŠ¤ ê°œìˆ˜",
                    ["5ê°œ", "10ê°œ", "15ê°œ", "20ê°œ"],
                    index=1
                )
            
            # ì„ íƒëœ ê°œìˆ˜ì— ë”°ë¼ ë°ì´í„° í•„í„°ë§
            count_map = {"5ê°œ": 5, "10ê°œ": 10, "15ê°œ": 15, "20ê°œ": 20}
            display_num = count_map[display_count]
            filtered_news = news_data[:display_num]
            
            # ë‰´ìŠ¤ ëª©ë¡ í‘œì‹œ
            st.subheader(f"ğŸ“‹ ìµœì‹  ë‰´ìŠ¤ {display_count}")
            
            for i, news in enumerate(filtered_news, 1):
                with st.container():
                    # ë‰´ìŠ¤ ì¹´ë“œ ìŠ¤íƒ€ì¼
                    st.markdown(f"""
                    <div style="
                        border: 1px solid #e0e0e0;
                        border-radius: 8px;
                        padding: 16px;
                        margin: 8px 0;
                        background-color: #f8f9fa;
                    ">
                        <h4 style="margin: 0 0 8px 0; color: #1f2937;">{i}. {news.title}</h4>
                        <p style="margin: 4px 0; color: #6b7280; font-size: 14px;">
                            ğŸ“° <strong>{news.source}</strong> | ğŸ“… {news.published}
                        </p>
                        <a href="{news.link}" target="_blank" style="
                            color: #3b82f6;
                            text-decoration: none;
                            font-weight: 500;
                        ">ğŸ”— ê¸°ì‚¬ ë³´ê¸°</a>
                    </div>
                    """, unsafe_allow_html=True)
            
            # ë‰´ìŠ¤ í†µê³„
            st.subheader("ğŸ“Š ë‰´ìŠ¤ í†µê³„")
            
            # ì¶œì²˜ë³„ ë‰´ìŠ¤ ìˆ˜
            source_stats = {}
            for news in filtered_news:
                source = news.source
                source_stats[source] = source_stats.get(source, 0) + 1
            
            if source_stats:
                fig = px.pie(
                    values=list(source_stats.values()),
                    names=list(source_stats.keys()),
                    title=f"ì¶œì²˜ë³„ {display_count} ë‰´ìŠ¤ ë¶„í¬"
                )
                st.plotly_chart(fig, use_container_width=True)
                
                # ì¶œì²˜ë³„ ë‰´ìŠ¤ ìˆ˜ í…Œì´ë¸”
                st.subheader("ğŸ“ˆ ì¶œì²˜ë³„ ë‰´ìŠ¤ ìˆ˜")
                source_df = pd.DataFrame([
                    {"ì¶œì²˜": source, "ë‰´ìŠ¤ ìˆ˜": count}
                    for source, count in source_stats.items()
                ])
                st.dataframe(source_df, use_container_width=True, hide_index=True)
        else:
            st.warning("ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

    @staticmethod
    def show_settings():
        """ì„¤ì • í˜ì´ì§€"""
        st.header("âš™ï¸ ì„¤ì •")
        
        st.subheader("ìºì‹œ ì„¤ì •")
        cache_duration = st.slider("ìºì‹œ ìœ ì§€ ì‹œê°„ (ë¶„)", 1, 60, 5)
        st.write(f"í˜„ì¬ ìºì‹œ ìœ ì§€ ì‹œê°„: {cache_duration}ë¶„")
        
        if st.button("ìºì‹œ ì´ˆê¸°í™”"):
            CacheManager.clear_cache()
            st.success("ìºì‹œê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        st.subheader("API ì„¤ì •")
        weather_api_key = st.text_input("OpenWeatherMap API í‚¤", type="password")
        if weather_api_key:
            st.success("API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # UI ì„¤ì •
    UIComponents.setup_page()
    UIComponents.initialize_session_state()
    
    # í—¤ë”
    st.markdown('<h1 class="main-header">ğŸ“Š DailyInfo - ë°ì´í„° ì •ë³´ ëŒ€ì‹œë³´ë“œ</h1>', unsafe_allow_html=True)
    
    # ì‚¬ì´ë“œë°” ë° ë©”ë‰´ ì²˜ë¦¬
    menu = UIComponents.create_sidebar()
    
    # ë©”ë‰´ë³„ ì²˜ë¦¬
    menu_handlers = {
        "ğŸ  ëŒ€ì‹œë³´ë“œ ê°œìš”": PageHandlers.show_dashboard_overview,
        "ğŸµ ë²…ìŠ¤ ì¼ê°„ ì°¨íŠ¸": PageHandlers.show_bugs_chart,
        "ğŸ“š ë„ì„œ ìˆœìœ„": PageHandlers.show_book_rankings,
        "ğŸŒ¤ï¸ ë‚ ì”¨ ì •ë³´": PageHandlers.show_weather_info,
        "ğŸ“° ë‰´ìŠ¤": PageHandlers.show_news,
        "âš™ï¸ ì„¤ì •": PageHandlers.show_settings
    }
    
    handler = menu_handlers.get(menu)
    if handler:
        handler()

if __name__ == "__main__":
    main() 