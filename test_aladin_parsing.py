import requests
from bs4 import BeautifulSoup
import re
from dataclasses import dataclass

@dataclass
class BookData:
    """ë„ì„œ ë°ì´í„° í´ë˜ìŠ¤"""
    rank: int
    title: str
    author: str
    publisher: str

def test_aladin_parsing():
    """ê°œì„ ëœ ì•Œë¼ë”˜ íŒŒì‹± ë¡œì§ í…ŒìŠ¤íŠ¸"""
    url = "https://www.aladin.co.kr/shop/common/wbest.aspx?BestType=NowBest&BranchType=2&CID=0&page=1&cnt=100&SortOrder=1"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'ko-KR,ko;q=0.9,en;q=0.8',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
    }
    
    try:
        print("ğŸ§ª ê°œì„ ëœ ì•Œë¼ë”˜ íŒŒì‹± ë¡œì§ í…ŒìŠ¤íŠ¸ ì¤‘...")
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        book_data = []
        
        # 1. ss_book_list í´ë˜ìŠ¤ë¥¼ ê°€ì§„ ìš”ì†Œë“¤ì—ì„œ ì±… ì •ë³´ ì¶”ì¶œ
        print("\nğŸ“š ss_book_listì—ì„œ ë°ì´í„° ì¶”ì¶œ:")
        book_lists = soup.find_all('div', class_='ss_book_list')
        print(f"ss_book_list ìš”ì†Œ ê°œìˆ˜: {len(book_lists)}")
        
        if book_lists:
            for i, book_list in enumerate(book_lists[:10]):  # ì²˜ìŒ 10ê°œë§Œ í…ŒìŠ¤íŠ¸
                book_list_text = book_list.get_text(strip=True)
                print(f"\në°•ìŠ¤ {i+1}: {book_list_text[:100]}...")
                
                # ìˆœìœ„ì™€ ì œëª© íŒ¨í„´ ì°¾ê¸°
                pattern1 = r'(\d+)\.\s*([ê°€-í£\s]+?)(?:\s+ì§€ìŒ|\s+ì €|\s+í¸ì§‘|\s+ê¸€|\s+ê·¸ë¦¼|\s+ì™¸|\s*$)'
                matches1 = re.findall(pattern1, book_list_text)
                
                if matches1:
                    for match in matches1:
                        rank = int(match[0])
                        title = match[1].strip()
                        
                        if len(title) > 3:
                            # ì €ìì™€ ì¶œíŒì‚¬ ì •ë³´ ì¶”ì¶œ ì‹œë„
                            author = "ì €ì ì •ë³´ ì—†ìŒ"
                            publisher = "ì¶œíŒì‚¬ ì •ë³´ ì—†ìŒ"
                            
                            # ì €ì íŒ¨í„´ ì°¾ê¸°
                            author_pattern = r'([ê°€-í£\s]+?)\s*ì§€ìŒ|([ê°€-í£\s]+?)\s*ì €|([ê°€-í£\s]+?)\s*í¸ì§‘'
                            author_matches = re.findall(author_pattern, book_list_text)
                            if author_matches:
                                for author_match in author_matches:
                                    if any(author_match):
                                        author = next(a for a in author_match if a).strip()
                                        break
                            
                            # ì¶œíŒì‚¬ íŒ¨í„´ ì°¾ê¸°
                            publisher_pattern = r'([ê°€-í£\s]+?)\s*\|\s*([ê°€-í£\s]+?)\s*\|'
                            publisher_matches = re.findall(publisher_pattern, book_list_text)
                            if publisher_matches:
                                publisher = publisher_matches[0][1].strip()
                            
                            print(f"  âœ… ì¶”ì¶œ: {rank}ìœ„ - {title[:30]}... (ì €ì: {author}, ì¶œíŒì‚¬: {publisher})")
                            
                            # ì¤‘ë³µ ì œê±°
                            existing_titles = [book.title for book in book_data]
                            if title not in existing_titles:
                                book_data.append(BookData(rank, title, author, publisher))
                            break
        
        # 2. ì±… ìƒí’ˆ ë§í¬ì—ì„œ ì œëª© ì¶”ì¶œ
        if not book_data:
            print("\nğŸ”— ì±… ìƒí’ˆ ë§í¬ì—ì„œ ë°ì´í„° ì¶”ì¶œ:")
            book_links = soup.find_all('a', href=lambda x: x and 'wproduct.aspx' in x)
            print(f"ì±… ìƒí’ˆ ë§í¬ ê°œìˆ˜: {len(book_links)}")
            
            for i, link in enumerate(book_links[:10]):
                link_text = link.get_text(strip=True)
                if len(link_text) > 5 and not link_text.startswith('http'):
                    rank = i + 1
                    title = link_text
                    author = "ì €ì ì •ë³´ ì—†ìŒ"
                    publisher = "ì¶œíŒì‚¬ ì •ë³´ ì—†ìŒ"
                    
                    print(f"  âœ… ì¶”ì¶œ: {rank}ìœ„ - {title[:30]}...")
                    
                    # ì¤‘ë³µ ì œê±°
                    existing_titles = [book.title for book in book_data]
                    if title not in existing_titles:
                        book_data.append(BookData(rank, title, author, publisher))
        
        # 3. ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ íŒ¨í„´ ë§¤ì¹­
        if not book_data:
            print("\nğŸ“ ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ íŒ¨í„´ ë§¤ì¹­:")
            all_text = soup.get_text()
            
            patterns = [
                r'(\d+)\.\s*([ê°€-í£\s]+?)(?:\s+ì§€ìŒ|\s+ì €|\s+í¸ì§‘|\s+ê¸€|\s+ê·¸ë¦¼|\s+ì™¸)',
                r'(\d+)\s*([ê°€-í£\s]+?)(?:\s+ì§€ìŒ|\s+ì €|\s+í¸ì§‘|\s+ê¸€|\s+ê·¸ë¦¼|\s+ì™¸)',
                r'ìˆœìœ„\s*(\d+)[^ê°€-í£]*([ê°€-í£\s]+?)(?:\s+ì§€ìŒ|\s+ì €|\s+í¸ì§‘|\s+ê¸€|\s+ê·¸ë¦¼|\s+ì™¸)',
            ]
            
            for pattern in patterns:
                matches = re.findall(pattern, all_text)
                if matches:
                    print(f"íŒ¨í„´ ë§¤ì¹˜: {len(matches)}ê°œ")
                    for match in matches[:5]:
                        rank = int(match[0])
                        title = match[1].strip()
                        
                        if len(title) > 3:
                            print(f"  âœ… ì¶”ì¶œ: {rank}ìœ„ - {title[:30]}...")
                            
                            # ì¤‘ë³µ ì œê±°
                            existing_titles = [book.title for book in book_data]
                            if title not in existing_titles:
                                book_data.append(BookData(rank, title, "ì €ì ì •ë³´ ì—†ìŒ", "ì¶œíŒì‚¬ ì •ë³´ ì—†ìŒ"))
                    break
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ“Š ìµœì¢… ì¶”ì¶œ ê²°ê³¼: {len(book_data)}ê°œ")
        for book in book_data[:10]:
            print(f"  {book.rank}ìœ„: {book.title[:40]}... (ì €ì: {book.author}, ì¶œíŒì‚¬: {book.publisher})")
        
        return book_data
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []

if __name__ == "__main__":
    test_aladin_parsing() 